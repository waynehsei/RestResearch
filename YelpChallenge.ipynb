{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.13 (default, Dec 20 2016 23:05:08)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "path = \"/Users/lakerwayne/Desktop/YelpChallenge\"\n",
    "phrases = pickle.load(open(path + '/word2one.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+\n",
      "| id|              review|               words|\n",
      "+---+--------------------+--------------------+\n",
      "|  0|Pallucci is a qua...|[pallucci, is, a,...|\n",
      "|  1|Came for dinner, ...|[came, for, dinne...|\n",
      "|  2|What a gem!!  My ...|[what, a, gem!!, ...|\n",
      "|  3|3.5 stars! I went...|[3.5, stars!, i, ...|\n",
      "|  4|Small, yet cozy r...|[small,, yet, coz...|\n",
      "+---+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.sql.functions import col, udf\n",
    "\n",
    "cuisine_path = path + \"/cuisines/review_Italian.txt\"\n",
    "reviews = []\n",
    "\n",
    "with open(cuisine_path, 'r') as txtfile:\n",
    "    rid = 0\n",
    "    for line in txtfile.readlines():\n",
    "        review = tuple([rid, line])\n",
    "        reviews.append(review)\n",
    "        rid += 1\n",
    "\n",
    "sentenceDataFrame = spark.createDataFrame(reviews, [\"id\", \"review\"])\n",
    "tokenizer = Tokenizer(inputCol=\"review\", outputCol=\"words\")\n",
    "tokenized = tokenizer.transform(sentenceDataFrame)\n",
    "tokenized.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "tokenized = remover.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+\n",
      "| id|              review|               words|            filtered|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "|  0|Pallucci is a qua...|[pallucci, is, a,...|[pallucci, quaint...|\n",
      "|  1|Came for dinner, ...|[came, for, dinne...|[came, dinner,, $...|\n",
      "|  2|What a gem!!  My ...|[what, a, gem!!, ...|[gem!!, , husband...|\n",
      "|  3|3.5 stars! I went...|[3.5, stars!, i, ...|[3.5, stars!, wen...|\n",
      "|  4|Small, yet cozy r...|[small,, yet, coz...|[small,, yet, coz...|\n",
      "+---+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import struct\n",
    "from pyspark.sql.types import *\n",
    "import re\n",
    "\n",
    "def cleanup_text(record):\n",
    "    text = record[3]\n",
    "    text_out = [re.sub('[^a-zA-Z0-9]','',word) for word in text]\n",
    "    return text_out\n",
    "\n",
    "# define udf with an array of tokenized words\n",
    "udf_cleantext = udf(cleanup_text , ArrayType(StringType()))\n",
    "clean_text = tokenized.withColumn(\"results\", udf_cleantext(struct([tokenized[x] for x in tokenized.columns])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|              review|               words|            filtered|             results|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|Pallucci is a qua...|[pallucci, is, a,...|[pallucci, quaint...|[pallucci, quaint...|\n",
      "|  1|Came for dinner, ...|[came, for, dinne...|[came, dinner,, $...|[came, dinner, 70...|\n",
      "|  2|What a gem!!  My ...|[what, a, gem!!, ...|[gem!!, , husband...|[gem, , husband, ...|\n",
      "|  3|3.5 stars! I went...|[3.5, stars!, i, ...|[3.5, stars!, wen...|[35, stars, went,...|\n",
      "|  4|Small, yet cozy r...|[small,, yet, coz...|[small,, yet, coz...|[small, yet, cozy...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_text.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# properly convert phrases to proper format\n",
    "nphrases = {}\n",
    "for s in phrases:\n",
    "    nphrases[s.keys()[0]] = s.values()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "| id|              review|               words|            filtered|             results|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "|  0|Pallucci is a qua...|[pallucci, is, a,...|[pallucci, quaint...|[pallucci, quaint...|\n",
      "|  1|Came for dinner, ...|[came, for, dinne...|[came, dinner,, $...|[came, dinner, 70...|\n",
      "|  2|What a gem!!  My ...|[what, a, gem!!, ...|[gem!!, , husband...|[gem, , husband, ...|\n",
      "|  3|3.5 stars! I went...|[3.5, stars!, i, ...|[3.5, stars!, wen...|[35, stars, went,...|\n",
      "|  4|Small, yet cozy r...|[small,, yet, coz...|[small,, yet, coz...|[small, yet, cozy...|\n",
      "+---+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "merge = clean_text\n",
    "merge.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           converted|\n",
      "+--------------------+\n",
      "|[pallucci, quaint...|\n",
      "|                  []|\n",
      "|[gem, , husband, ...|\n",
      "|[35, stars, went,...|\n",
      "|[small, yet, cozy...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def words2one(text):\n",
    "    list_of_words = text[4]\n",
    "    results = list_of_words\n",
    "    idx = 0\n",
    "    num_of_change=0\n",
    "    for i, w in enumerate(list_of_words):\n",
    "        idx = i-num_of_change\n",
    "        if i==len(list_of_words)-1:\n",
    "                continue\n",
    "        elif w in nphrases and nphrases[w]==list_of_words[i+1]:\n",
    "            results[idx] = results[idx]+\"_\"+results[idx+1]\n",
    "            results = results[:idx+1] + results[idx+2:]\n",
    "            num_of_change += 1\n",
    "    if num_of_change==0:\n",
    "        return []\n",
    "    return results\n",
    "\n",
    "udf_convert = udf(words2one, ArrayType(StringType()))\n",
    "ctext = merge.withColumn(\"converted\", udf_convert(struct([merge[y] for y in merge.columns])))\n",
    "ctext.select(\"converted\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=0, inputCol=\"converted\", outputCol=\"vectors\")\n",
    "model = word2Vec.setNumPartitions(10).fit(ctext.select(\"converted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_of_phrases = []\n",
    "for s in nphrases.items():\n",
    "    list_of_phrases.append(s[0] + \"_\" + s[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['word', 'vector']\n"
     ]
    }
   ],
   "source": [
    "print model.getVectors().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------------+\n",
      "|          word|              vector|\n",
      "+--------------+--------------------+\n",
      "|    thats_fine|[-0.8186696171760...|\n",
      "|      long_for|[0.02426917850971...|\n",
      "|elbow_macaroni|[0.21944025158882...|\n",
      "|  pickle_chips|[0.68999654054641...|\n",
      "|       ging_es|[1.95766067504882...|\n",
      "+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "domain = model.getVectors().where(col(\"word\").isin(list_of_phrases))\n",
    "domain.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _round(text):\n",
    "    vectors = text[1]\n",
    "    for v in enumerate(vectors):\n",
    "        v = round(v,5)\n",
    "    return vectors\n",
    "\n",
    "rdomain = domain\n",
    "udf_round = udf(_round, ArrayType(StringType()))\n",
    "rdomain = rdomain.withColumn(\"round\", udf_round(struct([rdomain[z] for z in rdomain.columns])))\n",
    "rdomain.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.clustering import KMeans\n",
    "domain.cache()\n",
    "kmeans = KMeans(featuresCol=\"vector\", predictionCol=\"prediction\", k=3, seed=50)\n",
    "kmodel = kmeans.fit(domain)\n",
    "# #kmeans = KMeans().setK(3).setSeed(50)\n",
    "# #model = kmeans.fit(domain.select('vector'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.getVectors().where(col(\"word\").isin(list_of_phrases)).toPandas().to_csv('cuisine_sim.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
